{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNG8TMKLgsIT",
        "outputId": "b8f0a76d-ee79-4f0d-e671-bda501fc9b1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# DO NOT RUN THIS FILE -- WAS USED IN COLAB TO CREATE CLASSIFIER MODEL!!!\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CXhHzqfi2i9",
        "outputId": "f1b010d1-a32a-411f-fdb5-78823f78142b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "# Check if GPU is running\n",
        "import torch\n",
        "print(torch.cuda.is_available())  # Should return True if GPU is active\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2U0Up8Oefa2E",
        "outputId": "061c0365-51bf-4ab5-eac5-c8587ec6afd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Average length of non-health queries: 48.967737789203085\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import torch\n",
        "import time\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Ensure GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load the dataset\n",
        "df_combined = pd.read_csv(\"/content/drive/MyDrive/qa_classifier/qa_dataset.csv\")\n",
        "\n",
        "# Step 1: Calculate the average length of non-health queries\n",
        "# We calculate the length of the 'combined_text' column for non-health queries\n",
        "non_health_lengths = df_combined[df_combined['label'] == 0]['combined_text'].apply(len)\n",
        "avg_non_health_length = non_health_lengths.mean()\n",
        "print(f\"Average length of non-health queries: {avg_non_health_length}\")\n",
        "\n",
        "# Step 2: Truncate health queries to the average length of non-health queries\n",
        "# We will truncate all health-related queries to this average length\n",
        "def truncate_text(text, length):\n",
        "    return text[:int(length)]  # Truncate the text to the desired length\n",
        "\n",
        "# Apply truncation only to health queries (label = 1)\n",
        "df_combined.loc[df_combined['label'] == 1, 'combined_text'] = df_combined[df_combined['label'] == 1]['combined_text'].apply(lambda x: truncate_text(x, avg_non_health_length))\n",
        "\n",
        "# Step 3: Balance the dataset by downsampling\n",
        "df_health = df_combined[df_combined['label'] == 1]  # Health-related queries\n",
        "df_non_health = df_combined[df_combined['label'] == 0]  # Non-health queries\n",
        "\n",
        "# Find the minimum size of the two classes\n",
        "min_size = min(len(df_health), len(df_non_health))\n",
        "\n",
        "# Downsample both classes to the minimum size\n",
        "df_health_balanced = df_health.sample(n=min_size, random_state=42)\n",
        "df_non_health_balanced = df_non_health.sample(n=min_size, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtEoVBFGgT1p",
        "outputId": "91b8051c-c2fc-47d3-dfed-e0b1b55c398f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label\n",
            "1    7780\n",
            "0    7780\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Combine the balanced classes and shuffle the dataset\n",
        "df_balanced = pd.concat([df_health_balanced, df_non_health_balanced]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Check the balance\n",
        "print(df_balanced['label'].value_counts())\n",
        "\n",
        "# Step 4: Split the data into features (X) and labels (y)\n",
        "X = df_balanced['combined_text']\n",
        "y = df_balanced['label']\n",
        "\n",
        "# Step 5: Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize the training data\n",
        "train_encodings = tokenizer(list(X_train), truncation=True, padding=True, max_length=128)\n",
        "test_encodings = tokenizer(list(X_test), truncation=True, padding=True, max_length=128)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "6ZyUq1hJgTwO"
      },
      "outputs": [],
      "source": [
        "# Dataset class\n",
        "class BinaryClassificationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# Create the datasets\n",
        "train_dataset = BinaryClassificationDataset(train_encodings, y_train.tolist())\n",
        "test_dataset = BinaryClassificationDataset(test_encodings, y_test.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "id": "zWDaWY7XgTs6",
        "outputId": "5677bf57-79d8-4704-e0bd-2fe98372f73a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2334' max='2334' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2334/2334 05:31, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.176200</td>\n",
              "      <td>0.139809</td>\n",
              "      <td>0.982969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.008600</td>\n",
              "      <td>0.007329</td>\n",
              "      <td>0.998393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.017700</td>\n",
              "      <td>0.002255</td>\n",
              "      <td>0.999357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.000265</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.010344</td>\n",
              "      <td>0.997751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.002100</td>\n",
              "      <td>0.048825</td>\n",
              "      <td>0.990039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.002295</td>\n",
              "      <td>0.999357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.021242</td>\n",
              "      <td>0.997429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.007016</td>\n",
              "      <td>0.998393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.026700</td>\n",
              "      <td>0.007999</td>\n",
              "      <td>0.998715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.000229</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.003111</td>\n",
              "      <td>0.999036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.051600</td>\n",
              "      <td>0.005560</td>\n",
              "      <td>0.999036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.003886</td>\n",
              "      <td>0.999036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.001650</td>\n",
              "      <td>0.999679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000879</td>\n",
              "      <td>0.999679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001884</td>\n",
              "      <td>0.999357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001910</td>\n",
              "      <td>0.999357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001914</td>\n",
              "      <td>0.999357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001921</td>\n",
              "      <td>0.999357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training completed in 0 hours, 5 minutes, and 31 seconds.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load BERT pre-trained model for binary classification\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2).to(device)\n",
        "\n",
        "# Evaluation metrics\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = torch.argmax(torch.tensor(logits), dim=-1)\n",
        "    accuracy = accuracy_score(labels, predictions.numpy())  # Ensure labels and predictions are both numpy arrays\n",
        "    return {\"accuracy\": accuracy}\n",
        "\n",
        "# Define the training arguments with Mixed Precision (FP16)\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',            # TensorBoard logs directory\n",
        "    logging_steps=10,                # Log every 10 steps\n",
        "    evaluation_strategy=\"steps\",     # Evaluate during training\n",
        "    eval_steps=100,\n",
        "    fp16=True,                       # Enable Mixed Precision Training (FP16)\n",
        "    save_total_limit=2,              # Save only the last 2 checkpoints to save space\n",
        "    load_best_model_at_end=True,     # Load the best model when training is finished\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics  # Pass the metric function here\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],  # Early stopping after 3 evaluation steps of no improvement\n",
        ")\n",
        "\n",
        "# Start time tracking\n",
        "start_time = time.time()\n",
        "\n",
        "# Start training\n",
        "trainer.train()\n",
        "\n",
        "# End time tracking\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "hours, rem = divmod(elapsed_time, 3600)\n",
        "minutes, seconds = divmod(rem, 60)\n",
        "print(f\"Training completed in {int(hours)} hours, {int(minutes)} minutes, and {int(seconds)} seconds.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "97jE5_digTnU",
        "outputId": "bea5baf0-4668-45b7-f68c-b94977f634d2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='195' max='195' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [195/195 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test dataset\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Test Accuracy: {eval_results['eval_accuracy']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "duJhpLc4nHuH",
        "outputId": "d3cf55a7-f54e-4c37-e2ba-3166d6fc3383"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train 4220                                Is early-onset glaucoma inherited ? Early-onset \n",
            "5589                                What are the treatments for autosomal recessive \n",
            "3547                                Is spinocerebellar ataxia type 3 inherited ? Thi\n",
            "4981                               where does the movie road to perdition take place\n",
            "14436                               How many people are affected by amyotrophic late\n",
            "                                            ...                                     \n",
            "5191                                   who wrote you must have been a beautiful baby\n",
            "13418                                                what kind of vw jetta do i have\n",
            "5390                                         where can a master at arms be stationed\n",
            "860      which of the following was not one of the functions of the friedmans bureau\n",
            "7270                                      how many books are in the one piece series\n",
            "Name: combined_text, Length: 12448, dtype: object\n",
            "y_train 4220     1\n",
            "5589     1\n",
            "3547     1\n",
            "4981     0\n",
            "14436    1\n",
            "        ..\n",
            "5191     0\n",
            "13418    0\n",
            "5390     0\n",
            "860      0\n",
            "7270     0\n",
            "Name: label, Length: 12448, dtype: int64\n",
            "X_test 99               What are the genetic changes related to esophage\n",
            "8450             How many people are affected by congenital myast\n",
            "2882     who was the first quarterback for the new orleans saints\n",
            "2177               who's running for attorney general in michigan\n",
            "12855            What are the genetic changes related to congenit\n",
            "                                   ...                           \n",
            "9844                       when did belfast become part of the uk\n",
            "7472             How to diagnose Pernicious Anemia ? Your doctor \n",
            "461           who acts as the chairman of the election commission\n",
            "12113            What is (are) Dyssynergia Cerebellaris Myoclonic\n",
            "4191             What causes Gastritis ? Common causes of gastrit\n",
            "Name: combined_text, Length: 3112, dtype: object\n",
            "y_test 99       1\n",
            "8450     1\n",
            "2882     0\n",
            "2177     0\n",
            "12855    1\n",
            "        ..\n",
            "9844     0\n",
            "7472     1\n",
            "461      0\n",
            "12113    1\n",
            "4191     1\n",
            "Name: label, Length: 3112, dtype: int64\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1541</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "label\n",
              "0    1571\n",
              "1    1541\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# pd.set_option('display.max_rows', 30)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 5000)\n",
        "pd.set_option('max_colwidth', 400)\n",
        "\n",
        "print('X_train', X_train)\n",
        "print('y_train', y_train)\n",
        "print('X_test', X_test)\n",
        "print('y_test', y_test)\n",
        "y_test.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-dO3L4igTcj",
        "outputId": "b8c3b6d2-61cb-4200-aa07-a18d94e2e107"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/qa_classifier/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/qa_classifier/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/qa_classifier/vocab.txt',\n",
              " '/content/drive/MyDrive/qa_classifier/added_tokens.json')"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the model\n",
        "model.save_pretrained('/content/drive/MyDrive/qa_classifier')\n",
        "tokenizer.save_pretrained('/content/drive/MyDrive/qa_classifier')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEhwKhxhfa2a",
        "outputId": "6c036e05-2293-4149-f89a-b94ad6049e6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: What are the side effects of taking aspirin?\n",
            "Prediction: Health\n",
            "\n",
            "Query: How can I manage my high blood pressure through diet?\n",
            "Prediction: Health\n",
            "\n",
            "Query: What are the symptoms of seasonal allergies?\n",
            "Prediction: Health\n",
            "\n",
            "Query: What is the best treatment for migraines?\n",
            "Prediction: Health\n",
            "\n",
            "Query: Can regular exercise help with controlling diabetes?\n",
            "Prediction: Health\n",
            "\n",
            "Query: What medications are typically prescribed for asthma?\n",
            "Prediction: Health\n",
            "\n",
            "Query: How often should I schedule a check-up with my doctor?\n",
            "Prediction: Non-Health\n",
            "\n",
            "Query: What is the best way to lower cholesterol levels naturally?\n",
            "Prediction: Health\n",
            "\n",
            "Query: What is a balanced diet plan for someone with heart disease?\n",
            "Prediction: Health\n",
            "\n",
            "Query: How do I know if I need to see a specialist for my back pain?\n",
            "Prediction: Health\n",
            "\n",
            "Query: What time is the next soccer game?\n",
            "Prediction: Non-Health\n",
            "\n",
            "Query: How do I install software on my computer?\n",
            "Prediction: Non-Health\n",
            "\n",
            "Query: What is the capital city of Australia?\n",
            "Prediction: Non-Health\n",
            "\n",
            "Query: Who won the Oscar for best picture in 2020?\n",
            "Prediction: Non-Health\n",
            "\n",
            "Query: Can you recommend some good books for summer reading?\n",
            "Prediction: Non-Health\n",
            "\n",
            "Query: What is the weather forecast for tomorrow?\n",
            "Prediction: Non-Health\n",
            "\n",
            "Query: How do I fix a flat tire on my bike?\n",
            "Prediction: Non-Health\n",
            "\n",
            "Query: When is the next presidential election?\n",
            "Prediction: Non-Health\n",
            "\n",
            "Query: What are the top 5 tourist destinations in Paris?\n",
            "Prediction: Non-Health\n",
            "\n",
            "Query: How can I learn a new programming language?\n",
            "Prediction: Non-Health\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check if GPU (CUDA) is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move the model to the selected device (GPU/CPU)\n",
        "model.to(device)\n",
        "\n",
        "# Sample queries (you can change these to test the model)\n",
        "test_queries = [\n",
        "    # Health-related queries (label = 1)\n",
        "    \"What are the side effects of taking aspirin?\",\n",
        "    \"How can I manage my high blood pressure through diet?\",\n",
        "    \"What are the symptoms of seasonal allergies?\",\n",
        "    \"What is the best treatment for migraines?\",\n",
        "    \"Can regular exercise help with controlling diabetes?\",\n",
        "    \"What medications are typically prescribed for asthma?\",\n",
        "    \"How often should I schedule a check-up with my doctor?\",\n",
        "    \"What is the best way to lower cholesterol levels naturally?\",\n",
        "    \"What is a balanced diet plan for someone with heart disease?\",\n",
        "    \"How do I know if I need to see a specialist for my back pain?\",\n",
        "\n",
        "    # Non-health-related queries (label = 0)\n",
        "    \"What time is the next soccer game?\",\n",
        "    \"How do I install software on my computer?\",\n",
        "    \"What is the capital city of Australia?\",\n",
        "    \"Who won the Oscar for best picture in 2020?\",\n",
        "    \"Can you recommend some good books for summer reading?\",\n",
        "    \"What is the weather forecast for tomorrow?\",\n",
        "    \"How do I fix a flat tire on my bike?\",\n",
        "    \"When is the next presidential election?\",\n",
        "    \"What are the top 5 tourist destinations in Paris?\",\n",
        "    \"How can I learn a new programming language?\"\n",
        "]\n",
        "\n",
        "# Tokenize the test queries\n",
        "inputs = tokenizer(test_queries, padding=True, truncation=True, return_tensors=\"pt\", max_length=128)\n",
        "\n",
        "# Move input tensors to the same device as the model\n",
        "inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "# Put the model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Make predictions\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "\n",
        "# Convert logits to predicted labels (0 = non-health, 1 = health)\n",
        "predictions = torch.argmax(logits, dim=-1)\n",
        "\n",
        "# Display results\n",
        "for i, query in enumerate(test_queries):\n",
        "    label = \"Health\" if predictions[i].item() == 1 else \"Non-Health\"\n",
        "    print(f\"Query: {query}\")\n",
        "    print(f\"Prediction: {label}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yd8pAY8lJUoQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
